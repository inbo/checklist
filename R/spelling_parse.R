spelling_parse_r <- function(r_file, wordlist) {
  raw_text <- readLines(r_file)

  # keep only roxygen2 metadata
  keep <- grepl("^#'", raw_text)
  if (!any(keep)) {
    return(list(NULL))
  }
  text <- ifelse(keep, raw_text, "")

  # remove multiline tags
  c("examples", "importFrom", "aliases") |>
    paste(collapse = "|") |>
    sprintf(fmt = "^#'\\s*@(%s)") |>
    grep(text) -> multiline
  while (length(multiline) > 0) {
    end_multiline <- c(
      which(text == ""), grep("#'\\s*@", text), length(text) + 1
    )
    end_multiline <- min(end_multiline[end_multiline > head(multiline, 1)]) - 1
    text[head(multiline, 1):end_multiline] <- ""
    multiline <- tail(multiline, -1)
  }

  # remove tag only lines
  c("export", "noRd") |>
    paste(collapse = "|") |>
    sprintf(fmt = "^#'\\s*@(%s)\\s*$") |>
    gsub("", text) -> text

  # remove only the tag
  c("concept", "description", "details", "return") |>
    paste(collapse = "|") |>
    sprintf(fmt = "^#'\\s*@(%s)") |>
    gsub("", text) -> text

  # remove the tag and the first word
  c("param", "reference") |>
    paste(collapse = "|") |>
    sprintf(fmt = "^#'\\s*@(%s)\\s+(\\w|\\.)+") |>
    gsub("", text, perl = TRUE) -> text

  # remove the entire line for certain tags
  c(
    "author", "docType", "export", "exportClass", "exportMethod", "family",
    "importClassesFrom", "importFrom", "inherit\\w*Params", "keywords", "name",
    "rdname", "seealso", "title", "template"
  ) |>
    paste(collapse = "|") |>
    sprintf(fmt = "^#'\\s*@(%s) .*") |>
    gsub("", text) -> text

  # remove roxygen comment signs
  text <- gsub("^#'", "", text)

  # remove backticks
  text <- gsub("`.*?`", "", text)
  # remove links to functions
  text <- gsub("\\[.*?\\(\\)\\]", "", text)
  # remove links
  text <- gsub("\\[(.*?)\\]\\(.*?\\)", "\\1", text)

  # remove bare URLs
  text <- gsub(
    "(https?|ftp):\\/{2}(\\w|\\.|\\/|#|-|=|\\?|:|_|\\(|\\))+", "", text
  )

  # remove equations
  text <- strip_eqn(text)

  list(spelling_check(
    text = text, filename = r_file, wordlist = wordlist
  ))
}

strip_eqn <- function(text) {
  which_eqn <- which(grepl("\\\\eqn\\s*\\{.*?\\}", text))
  if (length(which_eqn) == 0) {
    return(text)
  }
  eqn <- text[which_eqn]
  while (any(grepl("\\\\eqn\\s*\\{.*?\\}", eqn))) {
    eqn <- gsub("(\\\\eqn.*?)(\\{[^\\{]*?\\})", "\\1", eqn, perl = TRUE)
  }
  eqn <- gsub("\\\\eqn(\\s*[^\\{]|$)", "", eqn)
  ok <- !grepl("\\\\eqn\\s*\\{", eqn)
  text[which_eqn[ok]] <- eqn[ok]
  return(text)
}

#' @importFrom tools RdTextFilter
spelling_parse_rd <- function(rd_file, macros, wordlist) {
  if (grepl("% Generated by roxygen2:", readLines(rd_file, n = 1))) {
    return(list(NULL))
  }
  text <- RdTextFilter(rd_file, macros = macros)
  # remove e-mail
  text <- gsub(email_regexp, "", text, perl = TRUE)
  # remove functions
  text <- gsub("[a-zA-Z0-9]+:{2,3}[\\w\\.]+\\(.*?\\)", "", text, perl = TRUE)
  # remove forward and backward slashes surrounded by whitespace
  text <- gsub("\\s[/\\\\]\\s", " ", text)
  text <- gsub("\\s[/\\\\]$", " ", text)
  text <- gsub("^[/\\\\]\\s", " ", text)
  # remove equations
  text <- strip_eqn(text)
  list(spelling_check(
    text = text, filename = rd_file, wordlist = wordlist
  ))
}

#' @importFrom assertthat assert_that
spelling_parse_md <- function(md_file, wordlist, x) {
  raw_text <- readLines(md_file)
  text <- spelling_parse_md_yaml(text = raw_text)
  # remove chunks
  chunks <- grep("^\\s*```", text)
  assert_that(
    length(chunks) %% 2 == 0,
    msg = paste("Odd number of chunk delimiters detected in", md_file)
  )
  while (length(chunks)) {
    text[chunks[1]:chunks[2]] <- ""
    chunks <- tail(chunks, -2)
  }
  # remove in line chunks
  text <- gsub("\\`r .*?`", "", text)
  # remove ignored sections
  start <- grep("<!-- spell-check: ignore:start\\s*-->", text)
  end <- grep("<!-- spell-check: ignore:end\\s*-->", text)
  assert_that(
    length(start) == length(end),
    msg = paste(
      "unmatched `spell-check: ignore:start` and `spell-check: ignore:end` in",
      md_file
    )
  )
  assert_that(
    all(start < end),
    msg = paste(
      "`spell-check: ignore:end` appears before `spell-check: ignore:start`",
      "found in", md_file
    )
  )
  assert_that(
    all(head(end, -1) < tail(start, -1)),
    msg = paste(
      "new `spell-check: ignore:start` found without closing the previous in",
      md_file
    )
  )
  while (length(start)) {
    text[start[1]:end[1]] <- ""
    start <- tail(start, -1)
    end <- tail(end, -1)
  }
  # remove ignored lines
  text <- gsub(".*<!-- spell-check: ignore\\s*-->.*", "", text)
  # remove bookdown references
  text <- gsub("\\\\@ref\\(.*?\\)", "", text)
  # remove bookdown anchor
  text <- gsub("\\{#.*?\\}", "", text)
  # remove bookdown text references
  text <- gsub("\\(ref:.*?\\)", "", text)
  # remove stand alone math
  text <- gsub("\\$\\$.*?\\$\\$", "", text)
  # remove inline math
  text <- gsub("\\$.*?\\$", "", text)
  # remove citation
  text <- gsub("\\S*@\\S+", "", text, perl = TRUE)
  # replace non braking spaces
  text <- gsub("&nbsp;", " ", text)
  # remove LaTeX commands
  text <- gsub("\\\\\\w+", "", text)
  # remove Markdown figuren
  text <- gsub(
    "!\\[((.|\n)*?)\\]\\(.*?\\)(\\{.*?\\})?\\\\?", " \\1 ", text, perl = TRUE
  )
  # remove Markdown urls
  text <- gsub("\\[(.*?)\\]\\(.+?\\)", " \\1 ", text)
  text <- gsub("\\[(.*?)\\]\\(.+?\\)", " \\1 ", text)
  text <- gsub(
    "(http|https|ftp):\\/\\/[\\w\\.\\/\\-\\%:\\?=#]+", "", text, perl = TRUE
  )
  # remove e-mail
  text <- gsub(email_regexp, "", text, perl = TRUE)
  # remove text between matching back ticks on the same line
  text <- gsub("`.+?`", "", text)
  # remove markdown comments
  text <- gsub("<!--.*?-->", "", text)
  # remove markdown superscript
  text <- gsub("\\^\\w*\\^", "", text)
  # remove markdown subscript
  text <- gsub("~\\w*~", "", text)
  # remove markdown settings
  text <- gsub("\\{\\.unnumbered\\}", "", text)
  # remove HTML image with alt tag while keeping the alt tag
  text <- gsub("<.*?alt ?= ?\"(.*?)\".*?>", "\"\\1\"", text)
  # remove HTML image without alt tag
  text <- gsub("<img.*?>", "", text)
  # remove HTML script
  text <- gsub("<script.*?>.*<\\/script>", "", text, ignore.case = TRUE)
  start <- grep("<script.*?>", text)
  end <- grep("<\\/script>", text)
  assert_that(
    length(start) == length(end),
    msg = paste("unmatched `<script>` and `</script>` in", md_file)
  )
  assert_that(
    all(start < end),
    msg = paste("`</script>` appears before `<script>` found in", md_file)
  )
  assert_that(
    all(head(end, -1) < tail(start, -1)),
    msg = paste("new `<script>` found without closing the previous in", md_file)
  )
  while (length(start)) {
    text[start[1]:end[1]] <- ""
    start <- tail(start, -1)
    end <- tail(end, -1)
  }
  # remove HTML div and p tags
  text <- gsub("<\\/?(div|p).*?>", "", text, ignore.case = TRUE)
  # remove forward and backward slashes surrounded by whitespace
  text <- gsub("\\s[/\\\\]\\s", " ", text)
  text <- gsub("\\s[/\\\\]$", " ", text)
  text <- gsub("^[/\\\\]\\s", " ", text)
  # remove quarto anchors
  text <- gsub("\\{#.*?\\}", "", text)
  # remove quarto caption options
  text <- gsub("^: (.*)\\{.*?\\}", "\\1", text)

  # remove markdown footnotes
  text <- gsub("\\[\\^.*?\\]", "", text)

  # extract other languages
  assert_that(
    length(
      grep("(\\[(.*?)\\]\\{lang=([a-z]{2}(-[A-Z]{2})?)\\}.*){2,}", text)
    ) == 0,
    msg = paste("Multiple `[]{lang=}` on the same line found in", md_file)
  )

  other_languages <- data.frame(
    line = integer(0), text = character(0), language = character(0)
  )
  inline_language <- grep("\\[.*?\\]\\{lang=[a-z]{2}(-[A-Z]{2})?\\}", text)
  other_languages <- data.frame(
    line = inline_language,
    text = gsub(
      ".*\\[(.*?)\\]\\{lang=([a-z]{2}(-[A-Z]{2})?)\\}.*", "\\1",
      text[inline_language]
    ),
    language = gsub(
      ".*\\[(.*?)\\]\\{lang=([a-z]{2}(-[A-Z]{2})?)\\}.*", "\\2",
      text[inline_language]
    )
  )
  text <- gsub("\\[(.*?)\\]\\{lang=([a-z]{2}(-[A-Z]{2})?)\\}", "", text)
  other_lang_start <- grep("^::: \\{.*?lang=[a-z]{2}(-[A-Z]{2})?.*?\\}", text)
  other_lang_end <- grep("^:::\\s*$", text)
  while (length(other_lang_start)) {
    other_lang_end <- other_lang_end[other_lang_end > min(other_lang_start)]
    assert_that(
      length(other_lang_end) >= length(other_lang_start),
      msg = "`::: {lang=}` without matching `:::` found"
    )
    other_languages <- rbind(
      other_languages,
      data.frame(
        line = seq(other_lang_start[1] + 1, other_lang_end[1] - 1),
        text = text[seq(other_lang_start[1] + 1, other_lang_end[1] - 1)],
        language = gsub(
          ".*lang=([a-z]{2}(-[A-Z]{2})).*", "\\1", text[other_lang_start[1]]
        )
      )
    )
    text[seq(other_lang_start[1], other_lang_end[1])] <- ""
    other_lang_start <- tail(other_lang_start, -1)
  }
  # remove quarto divs
  divs <- grep("^:::", text)
  assert_that(
    length(divs) %% 2 == 0,
    msg = paste("Odd number of div (`:::`) delimiters detected in", md_file)
  )
  while (length(divs)) {
    text[c(divs[1], divs[2])] <- ""
    divs <- tail(divs, -2)
  }

  main_language <- spelling_check(
    text = text, raw_text = raw_text, filename = md_file, wordlist = wordlist
  )
  other_languages <- vapply(
    unique(other_languages$language), empty_text = rep("", length(raw_text)),
    FUN.VALUE = vector(mode = "list", length = 1), input = other_languages,
    raw_text = raw_text, md_file = md_file,
    FUN = function(lang, input, empty_text, raw_text, md_file) {
      empty_text[input[input$language == lang, "line"]] <-
        input[input$language == lang, "text"]
      list(spelling_check(
        text = empty_text, raw_text = raw_text, filename = md_file,
        wordlist = spelling_wordlist(
          lang = gsub("-", "_", lang), root = x$get_path, package = x$package
        )
      ))
    }
  )
  list(do.call(rbind, c(other_languages, list(main_language))))
}

#' @importFrom utils head
spelling_parse_md_yaml <- function(text) {
  header <- head(grep("---", text), 2)
  if (length(header) < 2) {
    return(text)
  }
  header <- header[1]:header[2]
  text[header][!grepl("(title|description)", text[header])] <- ""
  text[header] <- gsub(".*?:(.*)", "\\1", text[header])
  return(text)
}
